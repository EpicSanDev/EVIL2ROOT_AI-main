import os
import logging
import asyncio
import schedule
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import json
import requests
import pandas as pd
import numpy as np
from dotenv import load_dotenv
import pathlib

from app.telegram_bot import TelegramBot
from app.models.news_retrieval import NewsRetriever
import yfinance as yf

# Importation des mod√®les existants
from app.models.price_prediction import PricePredictionModel
from app.models.sentiment_analysis import SentimentAnalyzer, MarketRegimeDetector
from app.models.transformer_model import FinancialTransformer
from app.models.risk_management import RiskManagementModel
from app.models.indicator_management import IndicatorManagementModel
from app.models.tp_sl_management import TpSlManagementModel

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/daily_analysis_bot.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('daily_analysis_bot')

class DailyAnalysisBot:
    """
    Bot qui g√©n√®re et envoie des analyses quotidiennes compl√®tes via Telegram.
    Ces analyses combinent des √©l√©ments techniques, fondamentaux, et des nouvelles r√©centes.
    Utilise Claude 3.7 via OpenRouter pour formuler des analyses compl√®tes et pertinentes.
    """
    
    def __init__(self, symbols: List[str]):
        """
        Initialise le bot d'analyse quotidienne
        
        Args:
            symbols: Liste des symboles √† analyser
        """
        # Charger les variables d'environnement
        load_dotenv()
        
        # Configuration de base
        self.symbols = symbols
        self.telegram_bot = TelegramBot()
        self.news_retriever = NewsRetriever()
        
        # Configuration OpenRouter pour Claude 3.7
        self.openrouter_api_key = os.environ.get('OPENROUTER_API_KEY', '')
        self.claude_model = os.environ.get('CLAUDE_MODEL', 'anthropic/claude-3.7-sonnet')
        
        # V√©rification des cl√©s API
        if not self.openrouter_api_key:
            logger.warning("OpenRouter API key not found. AI analysis will be limited.")
        else:
            # Log a portion of the key for debugging (only first 8 chars)
            key_preview = self.openrouter_api_key[:8] + "..." if len(self.openrouter_api_key) > 8 else "invalid"
            logger.info(f"OpenRouter API key configured: {key_preview}...")
        
        # Horaires d'analyse
        self.analysis_schedule = [
            "09:00",  # Analyse pr√©-march√©
            "12:30",  # Analyse de mi-journ√©e
            "16:30",  # Analyse de cl√¥ture
            "20:00"   # Analyse r√©capitulative
        ]
        
        # R√©pertoire des mod√®les
        self.models_dir = os.environ.get('MODELS_DIR', 'saved_models')
        
        # Initialisation des mod√®les de pr√©diction
        logger.info("Initializing prediction models...")
        self.price_prediction_models = {}
        self.transformer_models = {}
        self.sentiment_analyzers = {}
        self.market_regime_detectors = {}
        self.risk_managers = {}
        self.indicator_managers = {}
        
        # Initialiser les mod√®les pour chaque symbole
        for symbol in symbols:
            self.price_prediction_models[symbol] = PricePredictionModel()
            self.sentiment_analyzers[symbol] = SentimentAnalyzer()
            self.market_regime_detectors[symbol] = MarketRegimeDetector()
            self.risk_managers[symbol] = RiskManagementModel()
            self.indicator_managers[symbol] = IndicatorManagementModel()
        
        # Transformer model sera initialis√© √† la demande pour √©conomiser de la m√©moire
        
        # Flag pour suivre l'√©tat d'entra√Ænement des mod√®les
        self.models_trained = False
        
        logger.info(f"Daily Analysis Bot initialized with {len(symbols)} symbols")
        
    def start_scheduled_analysis(self):
        """D√©marre les analyses planifi√©es selon l'horaire configur√©"""
        # V√©rifier et entra√Æner les mod√®les avant de commencer
        if not self.models_trained:
            asyncio.run(self.telegram_bot.send_message("üìä *PR√âPARATION DES MOD√àLES D'ANALYSE* üìä\n\nEntra√Ænement des mod√®les en cours... Veuillez patienter."))
            self.train_all_models()
            asyncio.run(self.telegram_bot.send_message("‚úÖ Entra√Ænement des mod√®les termin√©. Les analyses vont d√©marrer."))
        
        # Configurer le planning des analyses
        for analysis_time in self.analysis_schedule:
            schedule.every().day.at(analysis_time).do(self.run_analysis_for_all_symbols)
        
        # Lancer l'analyse initiale imm√©diatement
        self.run_analysis_for_all_symbols()
        
        logger.info(f"Scheduled analyses set up for: {', '.join(self.analysis_schedule)}")
        
        # Boucle principale pour ex√©cuter les t√¢ches planifi√©es
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # V√©rifier toutes les minutes
        except KeyboardInterrupt:
            logger.info("Scheduled analysis stopped by user")
    
    def train_all_models(self):
        """Entra√Æne tous les mod√®les n√©cessaires pour les analyses"""
        logger.info("Starting model training for all symbols...")
        
        try:
            # Entra√Æner les mod√®les pour chaque symbole
            for symbol in self.symbols:
                logger.info(f"Training models for {symbol}...")
                
                # R√©cup√©rer les donn√©es historiques pour l'entra√Ænement
                try:
                    # Utiliser une p√©riode plus longue pour l'entra√Ænement (5 ans au lieu de 2)
                    market_data = self.fetch_market_data(symbol, period="5y", interval="1d")
                    
                    # Entra√Æner le mod√®le de pr√©diction de prix
                    self._train_price_model(symbol, market_data)
                    
                    # Entra√Æner le mod√®le de sentiment
                    self._train_sentiment_model(symbol, market_data)
                    
                    # Entra√Æner le mod√®le de risque
                    self._train_risk_model(symbol, market_data)
                    
                    # Entra√Æner le mod√®le d'indicateurs
                    self._train_indicator_model(symbol, market_data)
                    
                    # Entra√Æner le mod√®le Transformer si activ√©
                    if os.environ.get('USE_TRANSFORMER_MODEL', 'true').lower() == 'true':
                        self._train_transformer_model(symbol, market_data)
                    
                    logger.info(f"All models trained successfully for {symbol}")
                    
                except Exception as e:
                    logger.error(f"Error training models for {symbol}: {e}")
            
            # Marquer les mod√®les comme entra√Æn√©s
            self.models_trained = True
            logger.info("All models trained successfully")
            
        except Exception as e:
            logger.error(f"Error during model training: {e}")
            raise
    
    def _train_price_model(self, symbol, market_data):
        """Entra√Æne le mod√®le de pr√©diction de prix"""
        logger.info(f"Training price prediction model for {symbol}")
        
        try:
            # V√©rifier si le mod√®le existe d√©j√†
            model_path = os.path.join(self.models_dir, f"{symbol}_price_model")
            
            if os.path.exists(model_path):
                # Charger le mod√®le existant
                logger.info(f"Loading existing price model for {symbol}")
                self.price_prediction_models[symbol].load(model_path)
            else:
                # Entra√Æner un nouveau mod√®le
                logger.info(f"Training new price model for {symbol}")
                # Use named parameters to ensure proper parameter passing
                self.price_prediction_models[symbol].train(data=market_data, symbol=symbol)
                
                # Sauvegarder le mod√®le
                pathlib.Path(self.models_dir).mkdir(exist_ok=True)
                self.price_prediction_models[symbol].save(model_path)
                
            logger.info(f"Price prediction model ready for {symbol}")
            
        except Exception as e:
            logger.error(f"Error training price model for {symbol}: {e}")
            raise
    
    def _train_sentiment_model(self, symbol, market_data):
        """Entra√Æne le mod√®le d'analyse de sentiment"""
        logger.info(f"Training sentiment analysis model for {symbol}")
        
        try:
            # V√©rifier si le mod√®le existe d√©j√†
            model_path = os.path.join(self.models_dir, f"{symbol}_sentiment_model")
            
            if os.path.exists(model_path):
                logger.info(f"Loading existing sentiment model for {symbol}")
                self.sentiment_analyzers[symbol].load(model_path)
            else:
                logger.info(f"Training new sentiment model for {symbol}")
                # R√©cup√©rer des donn√©es suppl√©mentaires pour l'entra√Ænement
                news = self.news_retriever.get_combined_news(symbol, max_results=50)
                self.sentiment_analyzers[symbol].train(market_data, news, symbol)
                
                # Sauvegarder le mod√®le
                pathlib.Path(self.models_dir).mkdir(exist_ok=True)
                self.sentiment_analyzers[symbol].save(model_path)
                
            logger.info(f"Sentiment analysis model ready for {symbol}")
            
        except Exception as e:
            logger.error(f"Error training sentiment model for {symbol}: {e}")
            raise
    
    def _train_risk_model(self, symbol, market_data):
        """Entra√Æne le mod√®le de gestion des risques"""
        logger.info(f"Training risk management model for {symbol}")
        
        try:
            # V√©rifier si le mod√®le existe d√©j√†
            model_path = os.path.join(self.models_dir, f"{symbol}_risk_model")
            
            if os.path.exists(model_path):
                logger.info(f"Loading existing risk model for {symbol}")
                self.risk_managers[symbol].load(model_path)
            else:
                logger.info(f"Training new risk model for {symbol}")
                self.risk_managers[symbol].train(market_data, symbol)
                
                # Sauvegarder le mod√®le
                pathlib.Path(self.models_dir).mkdir(exist_ok=True)
                self.risk_managers[symbol].save(model_path)
                
            logger.info(f"Risk management model ready for {symbol}")
            
        except Exception as e:
            logger.error(f"Error training risk model for {symbol}: {e}")
            raise
    
    def _train_indicator_model(self, symbol, market_data):
        """Entra√Æne le mod√®le de gestion des indicateurs"""
        logger.info(f"Training indicator management model for {symbol}")
        
        try:
            # V√©rifier si le mod√®le existe d√©j√†
            model_path = os.path.join(self.models_dir, f"{symbol}_indicator_model")
            
            if os.path.exists(model_path):
                logger.info(f"Loading existing indicator model for {symbol}")
                self.indicator_managers[symbol].load(model_path)
            else:
                logger.info(f"Training new indicator model for {symbol}")
                self.indicator_managers[symbol].train(market_data, symbol)
                
                # Sauvegarder le mod√®le
                pathlib.Path(self.models_dir).mkdir(exist_ok=True)
                self.indicator_managers[symbol].save(model_path)
                
            logger.info(f"Indicator management model ready for {symbol}")
            
        except Exception as e:
            logger.error(f"Error training indicator model for {symbol}: {e}")
            raise
    
    def _train_transformer_model(self, symbol, market_data):
        """Entra√Æne le mod√®le Transformer pour les pr√©dictions avanc√©es"""
        logger.info(f"Training transformer model for {symbol}")
        
        try:
            # V√©rifier si le mod√®le existe d√©j√†
            model_path = os.path.join(self.models_dir, f"{symbol}_transformer_model")
            scaler_path = os.path.join(self.models_dir, f"{symbol}_transformer_scalers.pkl")
            
            if os.path.exists(model_path) and os.path.exists(scaler_path):
                logger.info(f"Loading existing transformer model for {symbol}")
                if symbol not in self.transformer_models:
                    # Initialiser le mod√®le transformateur
                    self.transformer_models[symbol] = FinancialTransformer()
                    
                self.transformer_models[symbol].load(model_path, scaler_path)
            else:
                logger.info(f"Training new transformer model for {symbol}")
                # Check if we have enough data for training, if not, fetch more
                if len(market_data) < 100:
                    logger.warning(f"Not enough data for {symbol}, fetching more historical data...")
                    try:
                        market_data = self.fetch_market_data(symbol, period="max", interval="1d")
                        if len(market_data) < 100:
                            logger.error(f"Still insufficient data for {symbol} to train model after fetching maximum history")
                            raise ValueError(f"Insufficient data for {symbol} to train transformer model")
                        logger.info(f"Successfully fetched extended data for {symbol}: {len(market_data)} data points")
                    except Exception as e:
                        logger.error(f"Failed to fetch extended data for {symbol}: {e}")
                        raise
                
                # Initialiser le mod√®le s'il n'existe pas
                if symbol not in self.transformer_models:
                    self.transformer_models[symbol] = FinancialTransformer(
                        input_sequence_length=30,
                        forecast_horizon=5,
                        d_model=64,
                        num_heads=4,
                        dropout_rate=0.1,
                        num_transformer_blocks=2
                    )
                
                # Entra√Æner le mod√®le
                self.transformer_models[symbol].train(
                    data=market_data,
                    target_column='Close',
                    epochs=50,
                    batch_size=32,
                    validation_split=0.2
                )
                
                # Sauvegarder le mod√®le
                pathlib.Path(self.models_dir).mkdir(exist_ok=True)
                self.transformer_models[symbol].save(model_path, scaler_path)
                
            logger.info(f"Transformer model ready for {symbol}")
            
        except Exception as e:
            logger.error(f"Error training transformer model for {symbol}: {e}")
            raise
    
    def run_analysis_for_all_symbols(self):
        """Ex√©cute l'analyse pour tous les symboles configur√©s"""
        current_time = datetime.now().strftime("%H:%M")
        logger.info(f"Starting scheduled analysis for all symbols at {current_time}")
        
        # V√©rifier si les mod√®les sont entra√Æn√©s
        if not self.models_trained:
            message = "‚ö†Ô∏è Les mod√®les d'analyse n'ont pas √©t√© entra√Æn√©s. Entra√Ænement en cours..."
            logger.warning("Models not trained. Training now before analysis.")
            asyncio.run(self.telegram_bot.send_message(message))
            self.train_all_models()
            asyncio.run(self.telegram_bot.send_message("‚úÖ Entra√Ænement des mod√®les termin√©. D√©but des analyses..."))
        
        # Envoyer un message initial
        asyncio.run(self.telegram_bot.send_message(f"üîé *ANALYSE DE MARCH√â* - {datetime.now().strftime('%d/%m/%Y %H:%M')} üîé\n\nPr√©paration des analyses pour {len(self.symbols)} actifs..."))
        
        # Analyser chaque symbole
        for symbol in self.symbols:
            try:
                analysis = self.generate_complete_analysis(symbol)
                asyncio.run(self.telegram_bot.send_message(analysis))
                # Attendre entre chaque analyse pour ne pas surcharger Telegram
                time.sleep(3)
            except Exception as e:
                logger.error(f"Error analyzing {symbol}: {e}")
                asyncio.run(self.telegram_bot.send_message(f"‚ùå Erreur lors de l'analyse de {symbol}: {str(e)}"))
                
        # Message de conclusion
        asyncio.run(self.telegram_bot.send_message(f"‚úÖ Analyses termin√©es pour {len(self.symbols)} actifs √† {current_time}"))
        logger.info(f"Completed scheduled analysis for all symbols at {current_time}")
    
    def fetch_market_data(self, symbol: str, period: str = "3mo", interval: str = "1d") -> pd.DataFrame:
        """
        R√©cup√®re les donn√©es de march√© pour un symbole donn√©
        
        Args:
            symbol: Symbole boursier
            period: P√©riode de temps ('1d', '5d', '1mo', '3mo', '6mo', '1y', '2y', '5y', 'max')
            interval: Intervalle entre les points de donn√©es ('1m', '2m', '5m', '15m', '30m', '60m', '90m', '1h', '1d', '5d', '1wk', '1mo', '3mo')
            
        Returns:
            DataFrame contenant les donn√©es de march√©
        """
        try:
            logger.info(f"Fetching market data for {symbol}")
            
            # Force to download data for a list even with a single symbol to ensure proper DataFrame creation
            # Explicitly set auto_adjust to False to maintain backward compatibility
            data = yf.download([symbol], period=period, interval=interval, progress=False, auto_adjust=False)
            
            if data.empty:
                logger.warning(f"No data received for {symbol} using period={period}. Attempting with maximum period...")
                # Try again with max period as fallback
                data = yf.download([symbol], period="max", interval=interval, progress=False, auto_adjust=False)
                
                if data.empty:
                    raise ValueError(f"No data received for {symbol} even with maximum period")
            
            # If 'Adj Close' is a MultiIndex DataFrame (when downloaded as a list), get the first level
            if isinstance(data.columns, pd.MultiIndex):
                # Select data for the specific symbol
                data = data.xs(symbol, axis=1, level=1, drop_level=True)
            
            # Check again if data is empty after processing
            if data.empty:
                raise ValueError(f"No valid data received for {symbol} after processing")
                
            # Ajouter les indicateurs techniques
            self._add_technical_indicators(data)
            
            # Log data size for debugging
            logger.info(f"Downloaded {len(data)} data points for {symbol}")
            
            return data
        except Exception as e:
            logger.error(f"Error fetching market data for {symbol}: {e}")
            raise
    
    def _add_technical_indicators(self, data: pd.DataFrame) -> None:
        """
        Ajoute les indicateurs techniques au DataFrame
        
        Args:
            data: DataFrame contenant les donn√©es OHLCV
        """
        # S'assurer que les donn√©es ont les colonnes n√©cessaires
        if data.empty or not all(col in data.columns for col in ['Open', 'High', 'Low', 'Close', 'Volume']):
            return
            
        # Moyennes mobiles
        data['SMA_20'] = data['Close'].rolling(window=20).mean()
        data['SMA_50'] = data['Close'].rolling(window=50).mean()
        data['SMA_200'] = data['Close'].rolling(window=200).mean()
        data['EMA_20'] = data['Close'].ewm(span=20, adjust=False).mean()
        
        # RSI (Relative Strength Index)
        delta = data['Close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        data['RSI'] = 100 - (100 / (1 + rs))
        
        # MACD (Moving Average Convergence Divergence)
        data['EMA_12'] = data['Close'].ewm(span=12, adjust=False).mean()
        data['EMA_26'] = data['Close'].ewm(span=26, adjust=False).mean()
        data['MACD'] = data['EMA_12'] - data['EMA_26']
        data['MACD_Signal'] = data['MACD'].ewm(span=9, adjust=False).mean()
        
        # Bandes de Bollinger
        data['BB_Middle'] = data['Close'].rolling(window=20).mean()
        data['BB_Std'] = data['Close'].rolling(window=20).std()
        data['BB_Upper'] = data['BB_Middle'] + (data['BB_Std'] * 2)
        data['BB_Lower'] = data['BB_Middle'] - (data['BB_Std'] * 2)
        
        # ATR (Average True Range)
        tr1 = abs(data['High'] - data['Low'])
        tr2 = abs(data['High'] - data['Close'].shift())
        tr3 = abs(data['Low'] - data['Close'].shift())
        tr = pd.DataFrame({'tr1': tr1, 'tr2': tr2, 'tr3': tr3}).max(axis=1)
        data['ATR'] = tr.rolling(window=14).mean()
        
        # Utiliser notre IndicatorManager pour ajouter des indicateurs plus avanc√©s
        try:
            # Extraire le symbol du premier √©l√©ment disponible pour passer au gestionnaire d'indicateurs
            symbol = list(self.indicator_managers.keys())[0]
            self.indicator_managers[symbol].add_technical_indicators(data)
        except Exception as e:
            logger.warning(f"Erreur lors de l'ajout d'indicateurs avanc√©s: {e}")
    
    def fetch_fundamental_data(self, symbol: str) -> Dict[str, Any]:
        """
        R√©cup√®re les donn√©es fondamentales pour un symbole donn√©
        
        Args:
            symbol: Symbole boursier
            
        Returns:
            Dictionnaire contenant les donn√©es fondamentales
        """
        try:
            # Pour les crypto-monnaies, on utilise une approche diff√©rente
            if '-USD' in symbol:
                # Pour les cryptos, on retourne des donn√©es basiques
                return {"type": "crypto", "symbol": symbol}
            
            # Pour les actions, on utilise yfinance
            ticker = yf.Ticker(symbol)
            
            # Informations de base
            info = ticker.info
            
            # Ratios financiers
            try:
                financial_data = {
                    "marketCap": info.get('marketCap'),
                    "forwardPE": info.get('forwardPE'),
                    "trailingPE": info.get('trailingPE'),
                    "priceToBook": info.get('priceToBook'),
                    "dividendYield": info.get('dividendYield', 0) * 100 if info.get('dividendYield') else 0,
                    "beta": info.get('beta'),
                    "fiftyTwoWeekHigh": info.get('fiftyTwoWeekHigh'),
                    "fiftyTwoWeekLow": info.get('fiftyTwoWeekLow')
                }
                
                return {
                    "type": "stock",
                    "symbol": symbol,
                    "name": info.get('shortName', symbol),
                    "sector": info.get('sector', 'N/A'),
                    "industry": info.get('industry', 'N/A'),
                    "financials": financial_data
                }
            except Exception as e:
                logger.warning(f"Error getting detailed financial data for {symbol}: {e}")
                # Retourner des informations basiques en cas d'erreur
                return {
                    "type": "stock", 
                    "symbol": symbol,
                    "name": info.get('shortName', symbol)
                }
                
        except Exception as e:
            logger.error(f"Error fetching fundamental data for {symbol}: {e}")
            return {"type": "unknown", "symbol": symbol, "error": str(e)}
    
    def generate_complete_analysis(self, symbol: str) -> str:
        """
        G√©n√®re une analyse compl√®te pour un symbole
        
        Args:
            symbol: Symbole boursier
            
        Returns:
            Analyse textuelle format√©e pour Telegram
        """
        logger.info(f"Generating complete analysis for {symbol}")
        
        try:
            # 1. R√©cup√©rer les donn√©es de march√©
            market_data = self.fetch_market_data(symbol)
            
            # 2. R√©cup√©rer les donn√©es fondamentales
            fundamental_data = self.fetch_fundamental_data(symbol)
            
            # 3. R√©cup√©rer les nouvelles r√©centes
            news = self.news_retriever.get_combined_news(symbol, max_results=5)
            
            # 4. Obtenir des pr√©dictions de prix
            price_predictions = self.predict_prices(symbol, market_data)
            
            # 5. Analyser le sentiment
            sentiment_analysis = self.analyze_sentiment(symbol, market_data, news)
            
            # 6. √âvaluer les risques
            risk_assessment = self.assess_risk(symbol, market_data, fundamental_data)
            
            # 7. Utiliser Claude 3.7 pour g√©n√©rer une analyse compl√®te
            analysis = self._generate_ai_analysis(
                symbol, 
                market_data, 
                fundamental_data, 
                news, 
                price_predictions, 
                sentiment_analysis, 
                risk_assessment
            )
            
            # Retourner l'analyse format√©e pour Telegram
            return analysis
            
        except Exception as e:
            logger.error(f"Error generating analysis for {symbol}: {e}")
            return f"‚ùå *ERREUR D'ANALYSE: {symbol}*\nUne erreur est survenue lors de la g√©n√©ration de l'analyse: {str(e)}"
    
    def _generate_ai_analysis(self, symbol: str, market_data: pd.DataFrame, 
                             fundamental_data: Dict[str, Any], news: List[Dict[str, Any]],
                             price_predictions: Dict[str, Any], sentiment_analysis: Dict[str, Any],
                             risk_assessment: Dict[str, Any]) -> str:
        """
        Utilise Claude 3.7 via OpenRouter pour g√©n√©rer une analyse compl√®te
        
        Args:
            symbol: Symbole boursier
            market_data: DataFrame des donn√©es de march√© avec indicateurs
            fundamental_data: Donn√©es fondamentales
            news: Liste des nouvelles r√©centes
            price_predictions: Pr√©dictions de prix
            sentiment_analysis: Analyse de sentiment
            risk_assessment: √âvaluation des risques
            
        Returns:
            Analyse format√©e pour Telegram
        """
        if not self.openrouter_api_key:
            logger.warning("OpenRouter API key not configured, using simplified analysis")
            return self._generate_simplified_analysis(
                symbol, market_data, fundamental_data, news, 
                price_predictions, sentiment_analysis, risk_assessment
            )
        
        try:
            # Pr√©parer les donn√©es pour l'analyse
            last_price = market_data['Close'].iloc[-1]
            price_change = market_data['Close'].iloc[-1] - market_data['Close'].iloc[-2]
            price_change_pct = (price_change / market_data['Close'].iloc[-2]) * 100
            
            # Calculer la tendance r√©cente (20 jours)
            recent_trend = "haussi√®re" if market_data['Close'].iloc[-1] > market_data['SMA_20'].iloc[-1] else "baissi√®re"
            
            # Tendance √† moyen terme (50 jours)
            medium_trend = "haussi√®re" if market_data['SMA_20'].iloc[-1] > market_data['SMA_50'].iloc[-1] else "baissi√®re"
            
            # Tendance √† long terme (200 jours si disponible)
            long_trend = "ind√©termin√©e"
            if 'SMA_200' in market_data.columns and not pd.isna(market_data['SMA_200'].iloc[-1]):
                long_trend = "haussi√®re" if market_data['SMA_50'].iloc[-1] > market_data['SMA_200'].iloc[-1] else "baissi√®re"
            
            # Donn√©es techniques pour le prompt
            technical_data = {
                "price": last_price,
                "change": f"{price_change:.2f} ({price_change_pct:.2f}%)",
                "recent_trend": recent_trend,
                "medium_trend": medium_trend,
                "long_trend": long_trend,
                "rsi": market_data['RSI'].iloc[-1] if 'RSI' in market_data.columns and not pd.isna(market_data['RSI'].iloc[-1]) else None,
                "macd": market_data['MACD'].iloc[-1] if 'MACD' in market_data.columns and not pd.isna(market_data['MACD'].iloc[-1]) else None,
                "macd_signal": market_data['MACD_Signal'].iloc[-1] if 'MACD_Signal' in market_data.columns and not pd.isna(market_data['MACD_Signal'].iloc[-1]) else None,
                "bb_upper": market_data['BB_Upper'].iloc[-1] if 'BB_Upper' in market_data.columns and not pd.isna(market_data['BB_Upper'].iloc[-1]) else None,
                "bb_lower": market_data['BB_Lower'].iloc[-1] if 'BB_Lower' in market_data.columns and not pd.isna(market_data['BB_Lower'].iloc[-1]) else None,
                "sma_20": market_data['SMA_20'].iloc[-1] if 'SMA_20' in market_data.columns and not pd.isna(market_data['SMA_20'].iloc[-1]) else None,
                "sma_50": market_data['SMA_50'].iloc[-1] if 'SMA_50' in market_data.columns and not pd.isna(market_data['SMA_50'].iloc[-1]) else None,
                "sma_200": market_data['SMA_200'].iloc[-1] if 'SMA_200' in market_data.columns and not pd.isna(market_data['SMA_200'].iloc[-1]) else None
            }
            
            # Construction du prompt pour Claude
            prompt = f"""En tant qu'analyste financier expert, g√©n√®re une analyse d√©taill√©e et compl√®te pour {symbol} ({fundamental_data.get('name', symbol)}) avec les informations suivantes:

### Donn√©es Techniques:
- Prix actuel: {technical_data['price']}
- Variation: {technical_data['change']}
- Tendance r√©cente (20j): {technical_data['recent_trend']}
- Tendance moyenne (50j): {technical_data['medium_trend']}
- Tendance longue (200j): {technical_data['long_trend']}
- RSI: {technical_data['rsi']:.2f if technical_data['rsi'] is not None else 'N/A'}
- MACD: {technical_data['macd']:.4f if technical_data['macd'] is not None else 'N/A'}
- Signal MACD: {technical_data['macd_signal']:.4f if technical_data['macd_signal'] is not None else 'N/A'}
- Bandes de Bollinger: Sup√©rieure = {technical_data['bb_upper']:.2f if technical_data['bb_upper'] is not None else 'N/A'}, Inf√©rieure = {technical_data['bb_lower']:.2f if technical_data['bb_lower'] is not None else 'N/A'}
- Moyennes mobiles: SMA20 = {technical_data['sma_20']:.2f if technical_data['sma_20'] is not None else 'N/A'}, SMA50 = {technical_data['sma_50']:.2f if technical_data['sma_50'] is not None else 'N/A'}, SMA200 = {technical_data['sma_200']:.2f if technical_data['sma_200'] is not None else 'N/A'}

### Pr√©dictions de Prix:
- Pr√©diction prix prochain jour: {price_predictions.get('next_day', 'N/A')}
- Niveau de confiance: {price_predictions.get('confidence', 0.5):.2f}

### Analyse de Sentiment:
- Score global: {sentiment_analysis.get('overall_score', 0.0)}
- Sentiment des nouvelles: {sentiment_analysis.get('news_sentiment', 'neutre')}
- Sentiment bas√© sur les prix: {sentiment_analysis.get('price_sentiment', 'neutre')}
- R√©gime de march√©: {sentiment_analysis.get('market_regime', 'normal')}
- Force de la tendance: {sentiment_analysis.get('trend_strength', 0.0)}

### √âvaluation des Risques:
- Niveau de risque: {risk_assessment.get('risk_level', 'mod√©r√©')}
- Volatilit√©: {risk_assessment.get('volatility', 0.0)}
- Ratio de Sharpe: {risk_assessment.get('sharpe_ratio', 0.0)}
- Drawdown maximum: {risk_assessment.get('max_drawdown', 0.0)}
- Risques cl√©s: {', '.join(risk_assessment.get('key_risks', ['Aucun risque majeur identifi√©']))}

### Donn√©es Fondamentales:
"""
            
            # Ajouter des donn√©es fondamentales pertinentes selon le type d'actif
            if fundamental_data.get('type') == 'stock':
                prompt += f"""- Secteur: {fundamental_data.get('sector', 'N/A')}
- Industrie: {fundamental_data.get('industry', 'N/A')}
"""
                
                # Ajouter les donn√©es financi√®res si disponibles
                financials = fundamental_data.get('financials', {})
                if financials:
                    prompt += f"""- Capitalisation boursi√®re: {financials.get('marketCap', 'N/A')}
- P/E (Trailing): {financials.get('trailingPE', 'N/A')}
- P/E (Forward): {financials.get('forwardPE', 'N/A')}
- Price to Book: {financials.get('priceToBook', 'N/A')}
- Rendement du dividende: {financials.get('dividendYield', 'N/A')}%
- Beta: {financials.get('beta', 'N/A')}
- 52 semaines - Haut: {financials.get('fiftyTwoWeekHigh', 'N/A')}
- 52 semaines - Bas: {financials.get('fiftyTwoWeekLow', 'N/A')}
"""
            elif fundamental_data.get('type') == 'crypto':
                prompt += "- Type d'actif: Crypto-monnaie\n"
            
            # Ajouter les nouvelles r√©centes
            prompt += "\n### Actualit√©s R√©centes:\n"
            if news:
                for idx, item in enumerate(news[:5], 1):
                    date_str = item.get('date', 'date inconnue')
                    prompt += f"{idx}. {item.get('title', 'Titre inconnu')} ({item.get('source', 'Source inconnue')}, {date_str})\n"
                    if 'summary' in item:
                        prompt += f"   R√©sum√©: {item.get('summary')}\n"
            else:
                prompt += "Aucune actualit√© r√©cente disponible.\n"
            
            prompt += """
### Instructions:
G√©n√®re une analyse compl√®te de cette valeur, organis√©e comme suit:
1. Une introduction concise avec la situation actuelle de l'actif
2. Analyse technique d√©taill√©e (tendance, supports/r√©sistances, signaux des indicateurs)
3. Analyse des pr√©dictions et du sentiment (perspectives √† court terme)
4. Analyse fondamentale (si pertinente selon le type d'actif)
5. √âvaluation des risques et points d'attention
6. Interpr√©tation des actualit√©s r√©centes et leur impact potentiel
7. Une conclusion avec perspective √† court, moyen et long terme
8. Un score global de sentiment (1-10) et une recommandation (Achat Fort, Achat, Neutre, Vente, Vente Forte)

Formate la r√©ponse avec Markdown pour Telegram (utilise *texte* pour le gras et _texte_ pour l'italique). Sois pr√©cis, professionnel et factuel.
"""

            # Faire la requ√™te √† OpenRouter pour Claude 3.7
            headers = {
                "Authorization": f"Bearer {self.openrouter_api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://evil2root.ai/",  # Required by OpenRouter
                "X-Title": "Evil2Root Trading AI"  # Helps OpenRouter identify your app
            }
            
            data = {
                "model": self.claude_model,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.3,
                "max_tokens": 4096,
                "stream": False
            }
            
            try:
                logger.info(f"Sending analysis request to OpenRouter for {symbol}")
                response = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=60  # Add timeout to avoid hanging
                )
                
                if response.status_code != 200:
                    logger.error(f"OpenRouter API error: {response.status_code} - {response.text}")
                    return self._generate_simplified_analysis(
                        symbol, market_data, fundamental_data, news, 
                        price_predictions, sentiment_analysis, risk_assessment
                    )
                    
                logger.info(f"Received successful response from OpenRouter for {symbol}")
                result = response.json()
                analysis_text = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                
                # Ajouter un en-t√™te avec le symbole et la date/heure
                header = f"üìä *ANALYSE COMPL√àTE: {symbol}* üìä\nüìÖ {datetime.now().strftime('%d/%m/%Y %H:%M')}\n\n"
                
                return header + analysis_text
                
            except Exception as e:
                logger.error(f"Error generating AI analysis for {symbol}: {e}")
                return self._generate_simplified_analysis(
                    symbol, market_data, fundamental_data, news, 
                    price_predictions, sentiment_analysis, risk_assessment
                )
            
        except Exception as e:
            logger.error(f"Error generating AI analysis for {symbol}: {e}")
            return self._generate_simplified_analysis(
                symbol, market_data, fundamental_data, news, 
                price_predictions, sentiment_analysis, risk_assessment
            )
    
    def _generate_simplified_analysis(self, symbol: str, market_data: pd.DataFrame, 
                                     fundamental_data: Dict[str, Any], news: List[Dict[str, Any]],
                                     price_predictions: Dict[str, Any] = None, 
                                     sentiment_analysis: Dict[str, Any] = None,
                                     risk_assessment: Dict[str, Any] = None) -> str:
        """
        G√©n√®re une analyse simplifi√©e bas√©e sur les donn√©es brutes, sans IA avanc√©e
        
        Args:
            symbol: Symbole boursier
            market_data: DataFrame des donn√©es de march√© avec indicateurs
            fundamental_data: Donn√©es fondamentales
            news: Liste des nouvelles r√©centes
            price_predictions: Pr√©dictions de prix (optionnel)
            sentiment_analysis: Analyse de sentiment (optionnel)
            risk_assessment: √âvaluation des risques (optionnel)
            
        Returns:
            Analyse format√©e pour Telegram
        """
        try:
            # Initialiser les dictionnaires si non fournis
            if price_predictions is None:
                price_predictions = {}
            if sentiment_analysis is None:
                sentiment_analysis = {}
            if risk_assessment is None:
                risk_assessment = {}
            
            # Calculer les √©l√©ments d'analyse de base
            last_price = market_data['Close'].iloc[-1]
            prev_price = market_data['Close'].iloc[-2]
            price_change = last_price - prev_price
            price_change_pct = (price_change / prev_price) * 100
            
            # Tendances
            short_trend = "haussi√®re üìà" if last_price > market_data['SMA_20'].iloc[-1] else "baissi√®re üìâ"
            medium_trend = "haussi√®re üìà" if market_data['SMA_20'].iloc[-1] > market_data['SMA_50'].iloc[-1] else "baissi√®re üìâ"
            
            # Indicateurs techniques
            rsi = market_data['RSI'].iloc[-1] if 'RSI' in market_data.columns and not pd.isna(market_data['RSI'].iloc[-1]) else None
            rsi_signal = ""
            if rsi is not None:
                if rsi > 70:
                    rsi_signal = "SURVENTE ‚ö†Ô∏è"
                elif rsi < 30:
                    rsi_signal = "SURACHAT ‚ö†Ô∏è"
                else:
                    rsi_signal = "NEUTRE ‚öñÔ∏è"
            
            # Signal MACD
            macd_signal = ""
            if 'MACD' in market_data.columns and 'MACD_Signal' in market_data.columns:
                macd = market_data['MACD'].iloc[-1]
                signal = market_data['MACD_Signal'].iloc[-1]
                
                if not pd.isna(macd) and not pd.isna(signal):
                    if macd > signal and macd > 0:
                        macd_signal = "POSITIF (ACHAT) üü¢"
                    elif macd < signal and macd < 0:
                        macd_signal = "N√âGATIF (VENTE) üî¥"
                    else:
                        macd_signal = "NEUTRE ‚öñÔ∏è"
            
            # Construire l'analyse
            analysis = f"üìä *ANALYSE: {symbol}* üìä\n"
            analysis += f"üìÖ {datetime.now().strftime('%d/%m/%Y %H:%M')}\n\n"
            
            # Informations de prix
            analysis += f"*Prix actuel:* {last_price:.2f}\n"
            analysis += f"*Variation:* {price_change:.2f} ({price_change_pct:.2f}%)\n\n"
            
            # Analyse technique
            analysis += "*üìà ANALYSE TECHNIQUE üìâ*\n"
            analysis += f"*Tendance court terme:* {short_trend}\n"
            analysis += f"*Tendance moyen terme:* {medium_trend}\n"
            if rsi is not None:
                analysis += f"*RSI (14):* {rsi:.2f} - {rsi_signal}\n"
            if macd_signal:
                analysis += f"*MACD:* {macd_signal}\n"
            
            # Niveaux importants
            analysis += "\n*Niveaux importants:*\n"
            if 'BB_Upper' in market_data.columns and 'BB_Lower' in market_data.columns:
                upper = market_data['BB_Upper'].iloc[-1]
                lower = market_data['BB_Lower'].iloc[-1]
                if not pd.isna(upper) and not pd.isna(lower):
                    analysis += f"- R√©sistance (BB): {upper:.2f}\n"
                    analysis += f"- Support (BB): {lower:.2f}\n"
            
            # Moyennes mobiles
            analysis += f"- SMA 20: {market_data['SMA_20'].iloc[-1]:.2f}\n"
            analysis += f"- SMA 50: {market_data['SMA_50'].iloc[-1]:.2f}\n"
            if 'SMA_200' in market_data.columns and not pd.isna(market_data['SMA_200'].iloc[-1]):
                analysis += f"- SMA 200: {market_data['SMA_200'].iloc[-1]:.2f}\n"
            
            # Pr√©dictions de prix (si disponibles)
            next_day_pred = price_predictions.get('next_day')
            if next_day_pred is not None:
                pred_change = ((next_day_pred / last_price) - 1) * 100
                analysis += f"\n*Pr√©diction J+1:* {next_day_pred:.2f} ({pred_change:.2f}%)\n"
                analysis += f"*Confiance:* {price_predictions.get('confidence', 0.5):.2f}\n"
            
            # Analyse du sentiment (si disponible)
            if sentiment_analysis:
                analysis += f"\n*Sentiment du march√©:* {sentiment_analysis.get('price_sentiment', 'neutre')}\n"
                if 'market_regime' in sentiment_analysis:
                    analysis += f"*R√©gime de march√©:* {sentiment_analysis['market_regime']}\n"
            
            # Analyse des risques (si disponible)
            if risk_assessment:
                analysis += f"\n*Niveau de risque:* {risk_assessment.get('risk_level', 'mod√©r√©')}\n"
                if risk_assessment.get('key_risks'):
                    analysis += "*Risques principaux:* " + ", ".join(risk_assessment['key_risks'][:2]) + "\n"
            
            # Analyse fondamentale (si disponible)
            if fundamental_data.get('type') == 'stock' and 'financials' in fundamental_data:
                analysis += "\n*üìä ANALYSE FONDAMENTALE üìä*\n"
                financials = fundamental_data.get('financials', {})
                
                if 'marketCap' in financials and financials['marketCap']:
                    # Formater la capitalisation boursi√®re
                    market_cap = financials['marketCap']
                    if market_cap >= 1_000_000_000:
                        market_cap_str = f"{market_cap/1_000_000_000:.2f}B"
                    else:
                        market_cap_str = f"{market_cap/1_000_000:.2f}M"
                    analysis += f"*Market Cap:* {market_cap_str}\n"
                
                if 'trailingPE' in financials and financials['trailingPE']:
                    analysis += f"*P/E:* {financials['trailingPE']:.2f}\n"
                
                if 'dividendYield' in financials and financials['dividendYield']:
                    analysis += f"*Div. Yield:* {financials['dividendYield']:.2f}%\n"
            
            # Actualit√©s r√©centes
            analysis += "\n*üì∞ ACTUALIT√âS R√âCENTES üì∞*\n"
            if news:
                for idx, item in enumerate(news[:3], 1):  # Limiter √† 3 actualit√©s
                    analysis += f"{idx}. {item.get('title', 'Titre inconnu')}\n"
                    if 'source' in item and 'date' in item:
                        analysis += f"   _{item['source']} - {item['date']}_\n"
            else:
                analysis += "_Aucune actualit√© r√©cente disponible_\n"
            
            # Conclusion simplifi√©e
            analysis += "\n*üìù CONCLUSION üìù*\n"
            
            # D√©terminer sentiment g√©n√©ral
            bullish_signals = 0
            bearish_signals = 0
            
            # Tendance des prix
            if short_trend == "haussi√®re üìà":
                bullish_signals += 1
            else:
                bearish_signals += 1
                
            if medium_trend == "haussi√®re üìà":
                bullish_signals += 1
            else:
                bearish_signals += 1
            
            # RSI
            if rsi is not None:
                if rsi < 30:
                    bullish_signals += 1
                elif rsi > 70:
                    bearish_signals += 1
            
            # MACD
            if macd_signal == "POSITIF (ACHAT) üü¢":
                bullish_signals += 1
            elif macd_signal == "N√âGATIF (VENTE) üî¥":
                bearish_signals += 1
            
            # Sentiment from sentiment analysis
            if sentiment_analysis.get('overall_score', 0) > 0.2:
                bullish_signals += 1
            elif sentiment_analysis.get('overall_score', 0) < -0.2:
                bearish_signals += 1
            
            # Pr√©diction de prix
            if next_day_pred is not None and next_day_pred > last_price:
                bullish_signals += 1
            elif next_day_pred is not None and next_day_pred < last_price:
                bearish_signals += 1
            
            # D√©terminer le sentiment g√©n√©ral
            if bullish_signals > bearish_signals + 1:
                sentiment = "FORTEMENT HAUSSIER üìàüìà"
                recommendation = "ACHAT FORT üü¢üü¢"
            elif bullish_signals > bearish_signals:
                sentiment = "HAUSSIER üìà"
                recommendation = "ACHAT üü¢"
            elif bearish_signals > bullish_signals + 1:
                sentiment = "FORTEMENT BAISSIER üìâüìâ"
                recommendation = "VENTE FORTE üî¥üî¥"
            elif bearish_signals > bullish_signals:
                sentiment = "BAISSIER üìâ"
                recommendation = "VENTE üî¥"
            else:
                sentiment = "NEUTRE ‚öñÔ∏è"
                recommendation = "NEUTRE ‚öñÔ∏è"
            
            # Ajouter conclusion
            analysis += f"*Sentiment g√©n√©ral:* {sentiment}\n"
            analysis += f"*Recommandation:* {recommendation}\n"
            
            return analysis
            
        except Exception as e:
            logger.error(f"Error generating simplified analysis for {symbol}: {e}")
            return f"‚ùå *ERREUR D'ANALYSE: {symbol}*\nUne erreur est survenue lors de la g√©n√©ration de l'analyse simplifi√©e: {str(e)}"
    
    def predict_prices(self, symbol: str, market_data: pd.DataFrame) -> Dict[str, Any]:
        """
        Utilise les mod√®les pour pr√©dire les prix futurs
        
        Args:
            symbol: Symbole boursier
            market_data: DataFrame contenant l'historique des prix
            
        Returns:
            Dictionnaire contenant les pr√©dictions
        """
        predictions = {}
        
        try:
            # Assurons-nous que nous avons suffisamment de donn√©es pour l'entra√Ænement
            if len(market_data) < 100:
                logger.warning(f"Donn√©es insuffisantes pour {symbol} pour entra√Æner le mod√®le")
                return {'next_day': None, 'five_day': None, 'confidence': 0.0}
            
            # Entra√Æner le mod√®le LSTM de base
            if symbol in self.price_prediction_models:
                # V√©rifier si le mod√®le a d√©j√† √©t√© entra√Æn√©
                model = self.price_prediction_models[symbol]
                try:
                    # Ensure we explicitly pass the symbol parameter
                    model.train(data=market_data, symbol=symbol)
                    next_day_prediction = model.predict(market_data, symbol)
                    predictions['next_day'] = next_day_prediction
                except Exception as e:
                    logger.error(f"Erreur lors de la pr√©diction LSTM pour {symbol}: {e}")
                    predictions['next_day'] = None
            
            # Utiliser le mod√®le Transformer pour des pr√©dictions √† plus long terme si nous avons suffisamment de donn√©es
            if len(market_data) >= 200:
                # Initialiser le mod√®le Transformer si n√©cessaire
                if symbol not in self.transformer_models:
                    self.transformer_models[symbol] = FinancialTransformer(
                        input_sequence_length=30,
                        forecast_horizon=5
                    )
                
                try:
                    transformer = self.transformer_models[symbol]
                    # Cette partie est simplifi√©e car le vrai entra√Ænement et pr√©diction
                    # prendraient beaucoup de temps et de ressources
                    if not hasattr(transformer, 'is_trained') or not transformer.is_trained:
                        logger.info(f"Le mod√®le Transformer pour {symbol} n'est pas entra√Æn√©. Utilisation de valeurs simul√©es.")
                        # Simuler une pr√©diction √† 5 jours - dans un cas r√©el, nous entra√Ænerions le mod√®le
                        last_price = market_data['Close'].iloc[-1]
                        five_day_prediction = last_price * (1 + 0.01 * np.random.randn(5))
                        transformer.is_trained = True  # Marquer comme "entra√Æn√©" pour √©viter des logs r√©p√©t√©s
                    else:
                        # Dans un cas r√©el, nous appellerions transformer.predict()
                        last_price = market_data['Close'].iloc[-1]
                        five_day_prediction = last_price * (1 + 0.01 * np.random.randn(5))
                    
                    predictions['five_day'] = five_day_prediction.tolist() if hasattr(five_day_prediction, 'tolist') else five_day_prediction
                except Exception as e:
                    logger.error(f"Erreur lors de la pr√©diction Transformer pour {symbol}: {e}")
                    predictions['five_day'] = None
            
            # Calculer une confiance bas√©e sur la volatilit√© r√©cente
            if 'ATR' in market_data.columns and not pd.isna(market_data['ATR'].iloc[-1]):
                atr = market_data['ATR'].iloc[-1]
                last_price = market_data['Close'].iloc[-1]
                # Plus l'ATR est √©lev√© par rapport au prix, moins nous sommes confiants
                volatility_ratio = atr / last_price
                confidence = max(0.3, min(0.9, 1.0 - volatility_ratio * 10))
                predictions['confidence'] = confidence
            else:
                predictions['confidence'] = 0.5  # Confiance moyenne par d√©faut
                
            return predictions
                
        except Exception as e:
            logger.error(f"Erreur lors de la pr√©diction de prix pour {symbol}: {e}")
            return {'next_day': None, 'five_day': None, 'confidence': 0.0}
    
    def analyze_sentiment(self, symbol: str, market_data: pd.DataFrame, news: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Analyse le sentiment du march√© combinant les donn√©es de prix et les nouvelles
        
        Args:
            symbol: Symbole boursier
            market_data: DataFrame contenant l'historique des prix
            news: Liste des nouvelles r√©centes
            
        Returns:
            Dictionnaire contenant les r√©sultats d'analyse de sentiment
        """
        sentiment_results = {
            'overall_score': 0.0,
            'news_sentiment': 'neutre',
            'price_sentiment': 'neutre',
            'market_regime': 'normal',
            'trend_strength': 0.0,
            'confidence': 0.5
        }
        
        try:
            # Analyse du sentiment des nouvelles
            if news and symbol in self.sentiment_analyzers:
                analyzer = self.sentiment_analyzers[symbol]
                
                # Extraire le texte des actualit√©s
                news_texts = []
                for news_item in news:
                    title = news_item.get('title', '')
                    summary = news_item.get('summary', '')
                    if title and summary:
                        news_texts.append(f"{title}. {summary}")
                    elif title:
                        news_texts.append(title)
                
                # Analyser le sentiment si nous avons des textes
                if news_texts:
                    # Dans un syst√®me r√©el, nous appellerions l'analyse de sentiment compl√®te
                    # Ici, simulons une analyse simplifi√©e pour √©viter la complexit√©
                    news_sentiments = []
                    for text in news_texts:
                        # Simuler une analyse de sentiment simple
                        if "positif" in text.lower() or "hausse" in text.lower() or "croissance" in text.lower():
                            news_sentiments.append(0.7)
                        elif "n√©gatif" in text.lower() or "baisse" in text.lower() or "chute" in text.lower():
                            news_sentiments.append(-0.5)
                        else:
                            news_sentiments.append(0.0)
                    
                    avg_news_sentiment = sum(news_sentiments) / len(news_sentiments)
                    sentiment_results['news_sentiment'] = "positif" if avg_news_sentiment > 0.2 else ("n√©gatif" if avg_news_sentiment < -0.2 else "neutre")
                    sentiment_results['overall_score'] = avg_news_sentiment
            
            # Analyse du sentiment bas√© sur le prix
            if len(market_data) >= 20:
                # Calculer la volatilit√© r√©cente
                if 'ATR' in market_data.columns:
                    recent_volatility = market_data['ATR'].iloc[-1] / market_data['Close'].iloc[-1]
                else:
                    recent_returns = market_data['Close'].pct_change().dropna()
                    recent_volatility = recent_returns.std()
                
                # Calculer le momentum r√©cent
                momentum = (market_data['Close'].iloc[-1] / market_data['Close'].iloc[-20] - 1.0)
                
                # Mettre √† jour le d√©tecteur de r√©gime de march√©
                regime_detector = self.market_regime_detectors[symbol]
                regime_info = regime_detector.update(momentum, recent_volatility)
                
                sentiment_results['market_regime'] = regime_info.get('regime', 'normal')
                sentiment_results['trend_strength'] = abs(momentum)
                sentiment_results['confidence'] = regime_info.get('confidence', 0.5)
                
                # √âvaluation du sentiment bas√© sur le prix
                if momentum > 0.03:
                    price_sentiment = "fortement positif"
                elif momentum > 0.01:
                    price_sentiment = "positif"
                elif momentum < -0.03:
                    price_sentiment = "fortement n√©gatif"
                elif momentum < -0.01:
                    price_sentiment = "n√©gatif"
                else:
                    price_sentiment = "neutre"
                
                sentiment_results['price_sentiment'] = price_sentiment
                
                # Ajuster le score global en tenant compte du sentiment de prix
                sentiment_results['overall_score'] = (sentiment_results['overall_score'] + momentum) / 2
            
            # Arrondir les valeurs num√©riques pour plus de lisibilit√©
            sentiment_results['overall_score'] = round(sentiment_results['overall_score'], 2)
            sentiment_results['trend_strength'] = round(sentiment_results['trend_strength'], 2)
            sentiment_results['confidence'] = round(sentiment_results['confidence'], 2)
            
            return sentiment_results
            
        except Exception as e:
            logger.error(f"Erreur lors de l'analyse de sentiment pour {symbol}: {e}")
            return sentiment_results
    
    def assess_risk(self, symbol: str, market_data: pd.DataFrame, fundamental_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        √âvalue les risques associ√©s √† l'investissement dans ce symbole
        
        Args:
            symbol: Symbole boursier
            market_data: DataFrame contenant l'historique des prix
            fundamental_data: Donn√©es fondamentales
            
        Returns:
            Dictionnaire contenant l'√©valuation des risques
        """
        risk_assessment = {
            'risk_level': 'mod√©r√©',
            'volatility': 0.0,
            'sharpe_ratio': 0.0,
            'max_drawdown': 0.0,
            'risk_reward_ratio': 0.0,
            'key_risks': []
        }
        
        try:
            # Utiliser le gestionnaire de risques
            if symbol in self.risk_managers:
                risk_manager = self.risk_managers[symbol]
                
                # Calculer les m√©triques de risque de base
                if len(market_data) >= 60:  # Avoir au moins 60 jours de donn√©es
                    returns = market_data['Close'].pct_change().dropna()
                    
                    # Volatilit√© (√©cart-type annualis√© des rendements quotidiens)
                    volatility = returns.std() * (252 ** 0.5)  # Annualisation
                    risk_assessment['volatility'] = round(volatility, 4)
                    
                    # Ratio de Sharpe (supposant un taux sans risque de 0.02 ou 2%)
                    risk_free_rate = 0.02 / 252  # Taux journalier
                    sharpe_ratio = (returns.mean() - risk_free_rate) / returns.std() * (252 ** 0.5)
                    risk_assessment['sharpe_ratio'] = round(sharpe_ratio, 2)
                    
                    # Drawdown maximum
                    cumulative = (1 + returns).cumprod()
                    running_max = cumulative.cummax()
                    drawdown = (cumulative / running_max - 1)
                    max_drawdown = drawdown.min()
                    risk_assessment['max_drawdown'] = round(max_drawdown, 4)
                    
                    # D√©finir le niveau de risque
                    if volatility > 0.4:
                        risk_level = "tr√®s √©lev√©"
                    elif volatility > 0.3:
                        risk_level = "√©lev√©"
                    elif volatility > 0.2:
                        risk_level = "mod√©r√© √† √©lev√©"
                    elif volatility > 0.1:
                        risk_level = "mod√©r√©"
                    else:
                        risk_level = "faible"
                    
                    risk_assessment['risk_level'] = risk_level
                    
                    # Ratio risque/r√©compense bas√© sur l'ATR et le momentum
                    if 'ATR' in market_data.columns and not pd.isna(market_data['ATR'].iloc[-1]):
                        atr = market_data['ATR'].iloc[-1]
                        momentum = returns.iloc[-20:].mean() * 20
                        
                        if abs(momentum) > 0:
                            risk_reward = abs(momentum) / (atr / market_data['Close'].iloc[-1])
                            risk_assessment['risk_reward_ratio'] = round(risk_reward, 2)
                    
                    # Identifier les risques cl√©s
                    key_risks = []
                    
                    # Risque de tendance
                    if market_data['SMA_50'].iloc[-1] < market_data['SMA_200'].iloc[-1]:
                        key_risks.append("Tendance baissi√®re √† long terme")
                    
                    # Risque de volatilit√©
                    if volatility > 0.3:
                        key_risks.append("Volatilit√© √©lev√©e")
                    
                    # Risque de momentum
                    if sharpe_ratio < 0:
                        key_risks.append("Momentum n√©gatif")
                    
                    # Risque fondamental pour les actions
                    if fundamental_data.get('type') == 'stock' and 'financials' in fundamental_data:
                        financials = fundamental_data['financials']
                        
                        # P/E √©lev√©
                        if financials.get('trailingPE') and financials['trailingPE'] > 30:
                            key_risks.append("Valorisation √©lev√©e (P/E > 30)")
                        
                        # Beta √©lev√©
                        if financials.get('beta') and financials['beta'] > 1.5:
                            key_risks.append(f"Beta √©lev√© ({financials['beta']:.2f})")
                    
                    risk_assessment['key_risks'] = key_risks
                
            return risk_assessment
            
        except Exception as e:
            logger.error(f"Erreur lors de l'√©valuation du risque pour {symbol}: {e}")
            return risk_assessment

def run_daily_analysis_bot():
    """
    Fonction principale pour ex√©cuter le bot d'analyse quotidienne
    """
    # Charger les variables d'environnement si ce n'est pas d√©j√† fait
    load_dotenv()
    
    # R√©cup√©rer la liste des symboles depuis les variables d'environnement
    symbols_str = os.environ.get('SYMBOLS', 'AAPL,GOOGL,MSFT,AMZN,TSLA,BTC-USD,ETH-USD')
    symbols = [s.strip() for s in symbols_str.split(',')]
    
    # V√©rifier si l'entra√Ænement forc√© est demand√©
    force_training = os.environ.get('FORCE_MODEL_TRAINING', 'false').lower() == 'true'
    
    # Cr√©er le bot d'analyse
    analysis_bot = DailyAnalysisBot(symbols)
    
    # Si l'entra√Ænement forc√© est demand√©, nettoyer les mod√®les existants
    if force_training:
        logger.info("Forced training mode activated - Clearing existing models")
        # Supprimer les anciens fichiers de mod√®les
        import shutil
        models_dir = os.environ.get('MODELS_DIR', 'saved_models')
        
        try:
            if os.path.exists(models_dir):
                # Supprimer tous les fichiers de mod√®les mais garder le r√©pertoire
                for filename in os.listdir(models_dir):
                    file_path = os.path.join(models_dir, filename)
                    if os.path.isfile(file_path) and filename != '.gitkeep':
                        os.unlink(file_path)
                logger.info(f"Cleared existing models from {models_dir}")
        except Exception as e:
            logger.warning(f"Error clearing models directory: {e}")
        
        # Forcer l'entra√Ænement des mod√®les
        analysis_bot.models_trained = False
    
    # D√©marrer le bot d'analyse
    analysis_bot.start_scheduled_analysis()

if __name__ == "__main__":
    run_daily_analysis_bot() 